import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
import pandas as pd
from env_qlearning import PenjualanEnv

# ==================================================
# âš¡ï¸ Setup
# ==================================================
st.set_page_config(page_title="Q-Learning Harga", layout="wide")

# ==================================================
# âš¡ï¸ Cek Model
# ==================================================
q_table_file = "q_table.npy"
if os.path.exists(q_table_file):
    q_table = np.load(q_table_file)
else:
    st.warning(f"âš ï¸ File `{q_table_file}` belum ditemukan. Silakan jalankan training dahulu.")
    q_table = None

# ==================================================
# âš¡ï¸ Load Environment
# ==================================================
env = PenjualanEnv()
env.unique_states = list(set(env.states))
env.n_states = len(env.unique_states)

# ==================================================
# âš¡ï¸ Sidebar Menu
# ==================================================
menu = st.sidebar.radio("Pilih Halaman", [
    "ğŸ“Š Visualisasi Q-table",
    "ğŸ“ˆ Evaluasi Policy",
    "ğŸ“‰ Grafik Reward",
    "âš™ï¸ Training Ulang",
    "ğŸ“Š Perbandingan Sebelum & Sesudah",
    "â„¹ï¸ Tentang"
])

# ==================================================
# âš¡ï¸ Fungsi Training
# ==================================================
def train_q_learning(env, alpha, gamma, epsilon, episodes):
    state_to_index = {s: i for i, s in enumerate(env.unique_states)}
    q_table = np.zeros((len(env.unique_states), env.n_actions))
    rewards_per_episode = []
    for episode in range(episodes):
        state = env.reset()
        total_reward = 0
        done = False
        while not done:
            state_idx = state_to_index[state]
            if np.random.rand() < epsilon:
                action = np.random.randint(env.n_actions)
            else:
                action = np.argmax(q_table[state_idx])
            result = env.step(action)
            if len(result) == 3:
                next_state, reward, done = result
            else:
                next_state, reward, done, _ = result
            next_state_idx = state_to_index[next_state]
            q_table[state_idx, action] += alpha * (
                reward + gamma * np.max(q_table[next_state_idx]) - q_table[state_idx, action]
            )
            total_reward += reward
            state = next_state
        rewards_per_episode.append(total_reward)
    return q_table, np.array(rewards_per_episode)

# ==================================================
# âš¡ï¸ Fungsi Evaluasi
# ==================================================
def evaluate_policy(env, q_table, n_trials=100):
    total_rewards = []
    for _ in range(n_trials):
        state = env.reset()
        done = False
        episode_reward = 0
        while not done:
            state_index = env.unique_states.index(state)
            action = np.argmax(q_table[state_index])
            result = env.step(action)
            if len(result) == 4:
                next_state, reward, done, _ = result
            elif len(result) == 3:
                next_state, reward, done = result
            else:
                raise ValueError("env.step() return format tidak valid.")
            episode_reward += reward
            state = next_state
        total_rewards.append(episode_reward)
    return np.mean(total_rewards)

# ==================================================
# âš¡ï¸ Menu: Visualisasi Q-table
# ==================================================
if menu == "ğŸ“Š Visualisasi Q-table":
    st.title("ğŸ“Š Strategi Harga: Q-table Heatmap")
    if q_table is not None:
        fig, ax = plt.subplots(figsize=(10, 6))
        sns.heatmap(q_table, annot=True, cmap="YlGnBu",
                    xticklabels=env.harga_list,
                    yticklabels=env.unique_states,
                    ax=ax)
        ax.set_xlabel("Harga (Action)")
        ax.set_ylabel("State")
        st.pyplot(fig)
    else:
        st.error("âŒ Tidak ditemukan `q_table.npy`.")

# ==================================================
# âš¡ï¸ Menu: Evaluasi Policy
# ==================================================
elif menu == "ğŸ“ˆ Evaluasi Policy":
    st.title("ğŸ“ˆ Evaluasi Policy")
    if q_table is not None:
        trials = st.slider("Jumlah Simulasi Episode", 10, 10000, 100, step=100)
        avg_reward = evaluate_policy(env, q_table, trials)
        st.success(f"ğŸ¯ Rata-rata reward dari {trials} simulasi: **{avg_reward:.2f}**")
    else:
        st.error("âŒ `q_table.npy` belum ditemukan.")

# ==================================================
# âš¡ï¸ Menu: Grafik Reward
# ==================================================
elif menu == "ğŸ“‰ Grafik Reward":
    st.title("ğŸ“‰ Grafik Reward per Episode")
    try:
        rewards = np.load("rewards_per_episode.npy")
        fig, ax = plt.subplots()
        ax.plot(rewards, label='Reward per Episode', color='green')
        ax.set_xlabel("Episode"); ax.set_ylabel("Reward"); ax.set_title("Reward per Episode (Training Progress)"); ax.legend()
        st.pyplot(fig)
    except FileNotFoundError:
        st.error("âŒ `rewards_per_episode.npy` tidak ditemukan.")

# ==================================================
# âš¡ï¸ Menu: Training Ulang
# ==================================================
elif menu == "âš™ï¸ Training Ulang":
    st.title("âš™ï¸ Training Ulang Q-Learning")
    alpha = st.number_input("Alpha (Learning rate)", 0.0, 1.0, 0.1, step=0.01)
    gamma = st.number_input("Gamma (Discount factor)", 0.0, 1.0, 0.9, step=0.01)
    epsilon = st.number_input("Epsilon (Exploration rate)", 0.0, 1.0, 0.1, step=0.01)
    episodes = st.number_input("Jumlah Episode", 100, 10000, 1000, step=100)

    if st.button("ğŸš€ Mulai Training"):
        with st.spinner("Training sedang berjalan..."):
            q_table_new, rewards = train_q_learning(env, alpha, gamma, epsilon, episodes)
            np.save("q_table.npy", q_table_new)
            np.save("rewards_per_episode.npy", rewards)
            st.success("âœ… Training selesai dan file disimpan.")

# ==================================================
# âš¡ï¸ Menu: Perbandingan Sebelum & Sesudah
# ==================================================
elif menu == "ğŸ“Š Perbandingan Sebelum & Sesudah":
    st.title("ğŸ“Š Perbandingan Data Sebelum vs Setelah Training")
    try:
        before_df = pd.read_csv("datapenjualan.csv")  # harus ada
        after_df = pd.read_csv("simulation_after_training.csv")  # harus ada
        before_total = before_df["profit"].sum()
        after_total = after_df["profit"].sum()

        st.write(f"ğŸ’µ Total Profit Sebelum Training: **{before_total:,.2f}**")
        st.write(f"ğŸš€ Total Profit Setelah Training: **{after_total:,.2f}**")

        fig, ax = plt.subplots()
        ax.bar(["Sebelum", "Sesudah"], [before_total, after_total], color=["red", "green"])
        ax.set_ylabel("Total Profit"); ax.set_title("Perbandingan Profit"); ax.grid(True)
        st.pyplot(fig)

    except FileNotFoundError as e:
        st.error(f"âŒ File tidak ditemukan: {e}")

# ==================================================
# âš¡ï¸ Menu: Tentang
# ==================================================
elif menu == "â„¹ï¸ Tentang":
    st.title("â„¹ï¸ Tentang Aplikasi")
    st.markdown("""
    Aplikasi ini dibuat sebagai bagian dari skripsi untuk mensimulasikan **Reinforcement Learning (Q-Learning)** 
    dalam konteks **penetapan harga produk**.

    **Fitur:**
    - Visualisasi Q-table (heatmap)
    - Evaluasi policy
    - Grafik reward per episode
    - Training ulang dengan hyperparameter custom
    - âœ… **Perbandingan Profit Sebelum vs Sesudah Training**

    **Author**: Zihu â€” AI Engineer & Pejuang Skripsi ğŸ§ ğŸ”¥  
    **Stack**: Python, Streamlit, NumPy, Matplotlib, Seaborn
    """)

# ==================================================
# âš¡ï¸ Footer
# ==================================================
st.markdown("---")
st.caption("Â© 2025 â€” Made with â¤ï¸ by Zihu | Powered by Streamlit")
